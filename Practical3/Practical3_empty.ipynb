{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyP+G4k0tGsXvFur6Fn4IxIS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Brief**\n","\n","Write the architecture of a SimpleUNet following the diagram shown during the lecture/in GitHub:\n","\n","Encoder: Define a convolutional block (conv_block) that will be repeated in each layer of the encoder. Define as well a maxpooling block (maxpool_block) that will also be repeated when necessary during the encoding (downsampling path). Hint: use torch.nn.Conv2d and remember you need to add by hand the activation function (use ReLU).\n","\n","Middle: define the middle or bottleneck part of the architecture.\n","\n","Decoder: Define the transposed convolutional blocks (transposed_block). Hint: use nn.ConvTranspose2d.\n","\n","Final layer: Define the final convolutional layer.\n","\n","Forward: Remember you need to define the forward pass of your class, with how each block will be called.\n","\n","In order to aid the optimisation process, include batch normalisation (nn.BatchNorm2d) and 50% dropout (nn.Dropout2d(0.5)). Where do think they should be placed?\n","\n","Note: There are different ways to build this architecture, here we will use PyTorch as we will test that we can load the pre-trained model provided."],"metadata":{"id":"sk7pEc5nOmOt"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVqt8rYyOi2O","executionInfo":{"status":"ok","timestamp":1708192901984,"user_tz":0,"elapsed":19895,"user":{"displayName":"Dr Lorena Escudero Sánchez","userId":"08749439295150862240"}},"outputId":"bb7756c5-530b-4d44-bef5-9251250c8d0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader\n","import matplotlib.pyplot as plt\n","!pip install torchmetrics\n","import torchmetrics\n","from torchmetrics.classification import BinaryAccuracy\n","import numpy as np\n","from torchsummary import summary\n","import cv2"]},{"cell_type":"code","source":["class SimpleUNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = ...\n","        self.maxpool1 = ...\n","        self.conv2 = ...\n","        self.maxpool2 = ...\n","        self.conv3 = ...\n","        self.maxpool3 = ...\n","\n","        self.middle = ...\n","\n","        self.upsample3 = ...\n","        self.upconv3 = ...\n","        self.upsample2 = ...\n","        self.upconv2 = ...\n","\n","        self.upsample1 = ...\n","        self.upconv1 = ...\n","\n","        self.final = ...\n","\n","    def conv_block(self, in_channels, out_channels, kernel_size, stride, padding):\n","       convolution = nn.Sequential(\n","                    ...\n","                    )\n","\n","       return convolution\n","\n","    def maxpool_block(self, kernel_size, stride, padding):\n","       maxpool = nn.Sequential(...)\n","       return maxpool\n","\n","    def transposed_block(self, in_channels, out_channels, kernel_size, stride, padding, output_padding):\n","       transposed = ...\n","       return transposed\n","\n","    def final_layer(self, in_channels, out_channels, kernel_size, stride, padding):\n","       final = ...\n","       return final\n","\n","    def forward(self, x):\n","        # downsampling part\n","        conv1 = ...\n","        maxpool1 = ...\n","        conv2 = ...\n","        maxpool2 = ...\n","        conv3 = ...\n","        maxpool3 = ...\n","\n","        # middle part\n","        middle = ...\n","\n","        # upsampling part\n","        upsample3 = ...\n","        upconv3 = ...\n","        upsample2 = ...\n","        upconv2 = ...\n","        upsample1 = ...\n","        upconv1 = ...\n","\n","        final_layer = ...\n","\n","        return final_layer"],"metadata":{"id":"tJJ_C4m1Osi-"},"execution_count":null,"outputs":[]}]}